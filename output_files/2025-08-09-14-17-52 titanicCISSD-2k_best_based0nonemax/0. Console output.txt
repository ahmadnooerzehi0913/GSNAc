--------------------------------
Dataset charecteristics BEFORE processing:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 891 entries, 0 to 890
Data columns (total 12 columns):
 #   Column       Non-Null Count  Dtype  
---  ------       --------------  -----  
 0   PassengerId  891 non-null    object 
 1   Name         891 non-null    object 
 2   Sex          891 non-null    object 
 3   Age          714 non-null    float64
 4   SibSp        891 non-null    int64  
 5   Parch        891 non-null    int64  
 6   Ticket       891 non-null    object 
 7   Fare         891 non-null    float64
 8   Cabin        204 non-null    object 
 9   Embarked     889 non-null    object 
 10  Pclass       891 non-null    int64  
 11  Survived     891 non-null    int64  
dtypes: float64(2), int64(4), object(6)
memory usage: 83.7+ KB
None
--------------------------------
--------------------------------
Dataset charecteristics AFTER processing:
<class 'pandas.core.frame.DataFrame'>
Index: 183 entries, passenger2 to passenger890
Data columns (total 10 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   Age         183 non-null    float64
 1   SibSp       183 non-null    int64  
 2   Parch       183 non-null    int64  
 3   Fare        183 non-null    float64
 4   Embarked_Q  183 non-null    bool   
 5   Embarked_S  183 non-null    bool   
 6   Sex_male    183 non-null    bool   
 7   Pclass_2    183 non-null    bool   
 8   Pclass_3    183 non-null    bool   
 9   class       183 non-null    object 
dtypes: bool(5), float64(2), int64(2), object(1)
memory usage: 9.5+ KB
None
--------------------------------
SVM Linear started..
SVM RBF started..
kNN started..
Gaussian RBF started..
Decision Tree started..
Random Forest started..
Naive Bayes Gaussian started..
AdaBoost started..
ANN - MLP started..
--------------------------------
Dataset charecteristics BEFORE processing:
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 891 entries, 0 to 890
Data columns (total 12 columns):
 #   Column       Non-Null Count  Dtype  
---  ------       --------------  -----  
 0   PassengerId  891 non-null    object 
 1   Name         891 non-null    object 
 2   Sex          891 non-null    object 
 3   Age          714 non-null    float64
 4   SibSp        891 non-null    int64  
 5   Parch        891 non-null    int64  
 6   Ticket       891 non-null    object 
 7   Fare         891 non-null    float64
 8   Cabin        204 non-null    object 
 9   Embarked     889 non-null    object 
 10  Pclass       891 non-null    int64  
 11  Survived     891 non-null    int64  
dtypes: float64(2), int64(4), object(6)
memory usage: 83.7+ KB
None
--------------------------------
--------------------------------
Dataset charecteristics AFTER processing:
<class 'pandas.core.frame.DataFrame'>
Index: 183 entries, passenger2 to passenger890
Data columns (total 8 columns):
 #   Column    Non-Null Count  Dtype  
---  ------    --------------  -----  
 0   Sex       183 non-null    object 
 1   Age       183 non-null    float64
 2   SibSp     183 non-null    int64  
 3   Parch     183 non-null    int64  
 4   Fare      183 non-null    float64
 5   Embarked  183 non-null    object 
 6   Pclass    183 non-null    int64  
 7   class     183 non-null    object 
dtypes: float64(2), int64(3), object(3)
memory usage: 12.9+ KB
None
--------------------------------
Raw feature importances (before optional selection step) are:
{'Sex': np.float64(23.86656679192856), 'Age': np.float64(2.810161431145183), 'SibSp': np.float64(0.16760488570264537), 'Parch': np.float64(0.48145059607666196), 'Fare': np.float64(0.4927151237759287), 'Embarked': np.float64(0.9430444644970595), 'Pclass': np.float64(0.4425598028669517)}
['categorical', 'numerical', 'numerical', 'numerical', 'numerical', 'categorical', 'categorical']
Final feature importances are:
{'Sex': np.float64(81.72), 'Age': np.float64(9.62), 'SibSp': np.float64(0.57), 'Parch': np.float64(1.65), 'Fare': np.float64(1.69), 'Embarked': np.float64(3.23), 'Pclass': np.float64(1.52)}
['categorical', 'numerical', 'numerical', 'numerical', 'numerical', 'categorical', 'categorical']
--------------------------------
Graph status: -Fold 1 d Initial raw graph
*nb_of_nodes 183
*average_degree_of_a_node 181.98907103825135
*nb_of_edges 16652
*average_weight_of_an_edge 0.4489199334831576
*minimum_weight_of_an_edge 0.00012559190809480203
*maximum_weight_of_an_edge 1.0
*Is graph connected? True
*Number of connected components: 1
--------------------------------
--------------------------------
Graph status: -Fold 1 e Decorated graph
*nb_of_nodes 183
*average_degree_of_a_node 181.98907103825135
*nb_of_edges 16652
*average_weight_of_an_edge 0.4489199334831576
*minimum_weight_of_an_edge 0.00012559190809480203
*maximum_weight_of_an_edge 1.0
*Is graph connected? True
*Number of connected components: 1
--------------------------------
--------------------------------
Graph status: -Fold 1 f Kernel of the graph
*nb_of_nodes 91
*average_degree_of_a_node 6.725274725274725
*nb_of_edges 306
*average_weight_of_an_edge 0.9311653990046083
*minimum_weight_of_an_edge 0.8167888273327059
*maximum_weight_of_an_edge 0.998769322583096
*Is graph connected? False
*Number of connected components: 3
--------------------------------
--------------------------------
Graph status: -Fold 1 g SNA metrics added to kernel
*nb_of_nodes 91
*average_degree_of_a_node 6.725274725274725
*nb_of_edges 306
*average_weight_of_an_edge 0.5877468675722046
*minimum_weight_of_an_edge 0.00010000000000021103
*maximum_weight_of_an_edge 1.0000000000000004
*Is graph connected? False
*Number of connected components: 3
--------------------------------
Fold: 1
Misclassification: 21 out of 92
Accuracy: 0.7717391304347826
--------------------------------
Graph status: -Fold 1 i Prediction graph
*nb_of_nodes 91
*average_degree_of_a_node 6.725274725274725
*nb_of_edges 306
*average_weight_of_an_edge 0.5877468675722046
*minimum_weight_of_an_edge 0.00010000000000021103
*maximum_weight_of_an_edge 1.0000000000000004
*Is graph connected? False
*Number of connected components: 3
--------------------------------
Raw feature importances (before optional selection step) are:
{'Sex': np.float64(52.00399707546773), 'Age': np.float64(10.872072886847123), 'SibSp': np.float64(2.684750691113355), 'Parch': np.float64(1.698929966865788), 'Fare': np.float64(5.146567709958421), 'Embarked': np.float64(0.8991782406583098), 'Pclass': np.float64(0.01483420831097136)}
['categorical', 'numerical', 'numerical', 'numerical', 'numerical', 'categorical', 'categorical']
Final feature importances are:
{'Sex': np.float64(70.93), 'Age': np.float64(14.83), 'SibSp': np.float64(3.66), 'Parch': np.float64(2.32), 'Fare': np.float64(7.02), 'Embarked': np.float64(1.23), 'Pclass': np.float64(0.02)}
['categorical', 'numerical', 'numerical', 'numerical', 'numerical', 'categorical', 'categorical']
--------------------------------
Graph status: -Fold 2 d Initial raw graph
*nb_of_nodes 183
*average_degree_of_a_node 181.98907103825135
*nb_of_edges 16652
*average_weight_of_an_edge 0.4798609959545628
*minimum_weight_of_an_edge 0.0020888743557071487
*maximum_weight_of_an_edge 1.0
*Is graph connected? True
*Number of connected components: 1
--------------------------------
--------------------------------
Graph status: -Fold 2 e Decorated graph
*nb_of_nodes 183
*average_degree_of_a_node 181.98907103825135
*nb_of_edges 16652
*average_weight_of_an_edge 0.4798609959545628
*minimum_weight_of_an_edge 0.0020888743557071487
*maximum_weight_of_an_edge 1.0
*Is graph connected? True
*Number of connected components: 1
--------------------------------
--------------------------------
Graph status: -Fold 2 f Kernel of the graph
*nb_of_nodes 92
*average_degree_of_a_node 6.478260869565218
*nb_of_edges 298
*average_weight_of_an_edge 0.9176304847096907
*minimum_weight_of_an_edge 0.7821424713697593
*maximum_weight_of_an_edge 1.0
*Is graph connected? False
*Number of connected components: 2
--------------------------------
--------------------------------
Graph status: -Fold 2 g SNA metrics added to kernel
*nb_of_nodes 92
*average_degree_of_a_node 6.478260869565218
*nb_of_edges 298
*average_weight_of_an_edge 0.6187089047026474
*minimum_weight_of_an_edge 0.00010000000000021103
*maximum_weight_of_an_edge 1.0000000000000004
*Is graph connected? False
*Number of connected components: 2
--------------------------------
Fold: 2
Misclassification: 26 out of 91
Accuracy: 0.7142857142857143
--------------------------------
Graph status: -Fold 2 i Prediction graph
*nb_of_nodes 92
*average_degree_of_a_node 6.478260869565218
*nb_of_edges 298
*average_weight_of_an_edge 0.6187089047026474
*minimum_weight_of_an_edge 0.00010000000000021103
*maximum_weight_of_an_edge 1.0000000000000004
*Is graph connected? False
*Number of connected components: 2
--------------------------------
---
SVM Linear performance in titanic dataset:
                CL-0        CL-1  accuracy   macro avg  weighted avg
precision   0.623188    0.850877  0.765027    0.737033      0.776225
recall      0.716667    0.788618  0.765027    0.752642      0.765027
f1-score    0.666667    0.818565  0.765027    0.742616      0.768763
support    60.000000  123.000000  0.765027  183.000000    183.000000
[[43 17]
 [26 97]]
---
SVM RBF performance in titanic dataset:
                CL-0        CL-1  accuracy   macro avg  weighted avg
precision   0.588235    0.826087  0.737705    0.707161      0.748103
recall      0.666667    0.772358  0.737705    0.719512      0.737705
f1-score    0.625000    0.798319  0.737705    0.711660      0.741493
support    60.000000  123.000000  0.737705  183.000000    183.000000
[[40 20]
 [28 95]]
---
kNN performance in titanic dataset:
                CL-0        CL-1  accuracy   macro avg  weighted avg
precision   0.573770    0.795082  0.721311    0.684426      0.722521
recall      0.583333    0.788618  0.721311    0.685976      0.721311
f1-score    0.578512    0.791837  0.721311    0.685175      0.721894
support    60.000000  123.000000  0.721311  183.000000    183.000000
[[35 25]
 [26 97]]
---
Gaussian RBF performance in titanic dataset:
                CL-0        CL-1  accuracy   macro avg  weighted avg
precision   0.555556    0.791667  0.710383    0.673611      0.714253
recall      0.583333    0.772358  0.710383    0.677846      0.710383
f1-score    0.569106    0.781893  0.710383    0.675499      0.712127
support    60.000000  123.000000  0.710383  183.000000    183.000000
[[35 25]
 [28 95]]
---
Decision Tree performance in titanic dataset:
                CL-0        CL-1  accuracy   macro avg  weighted avg
precision   0.631579    0.809524  0.754098    0.720551      0.751181
recall      0.600000    0.829268  0.754098    0.714634      0.754098
f1-score    0.615385    0.819277  0.754098    0.717331      0.752427
support    60.000000  123.000000  0.754098  183.000000    183.000000
[[ 36  24]
 [ 21 102]]
---
Random Forest performance in titanic dataset:
                CL-0        CL-1  accuracy   macro avg  weighted avg
precision   0.698113    0.823077  0.786885    0.760595      0.782105
recall      0.616667    0.869919  0.786885    0.743293      0.786885
f1-score    0.654867    0.845850  0.786885    0.750359      0.783233
support    60.000000  123.000000  0.786885  183.000000    183.000000
[[ 37  23]
 [ 16 107]]
---
Naive Bayes Gaussian performance in titanic dataset:
                CL-0        CL-1  accuracy   macro avg  weighted avg
precision   0.373016    0.771930  0.497268    0.572473      0.641138
recall      0.783333    0.357724  0.497268    0.570528      0.497268
f1-score    0.505376    0.488889  0.497268    0.497133      0.494295
support    60.000000  123.000000  0.497268  183.000000    183.000000
[[47 13]
 [79 44]]
---
AdaBoost performance in titanic dataset:
                CL-0        CL-1  accuracy   macro avg  weighted avg
precision   0.690909    0.828125  0.786885    0.759517      0.783136
recall      0.633333    0.861789  0.786885    0.747561      0.786885
f1-score    0.660870    0.844622  0.786885    0.752746      0.784375
support    60.000000  123.000000  0.786885  183.000000    183.000000
[[ 38  22]
 [ 17 106]]
---
ANN - MLP performance in titanic dataset:
                CL-0        CL-1  accuracy   macro avg  weighted avg
precision   0.564516    0.793388  0.715847    0.678952      0.718348
recall      0.583333    0.780488  0.715847    0.681911      0.715847
f1-score    0.573770    0.786885  0.715847    0.680328      0.717012
support    60.000000  123.000000  0.715847  183.000000    183.000000
[[35 25]
 [27 96]]
---
GSNAc performance in titanic dataset:
                CL-0        CL-1  accuracy   macro avg  weighted avg
precision   0.568421    0.931818  0.743169    0.750120      0.812672
recall      0.900000    0.666667  0.743169    0.783333      0.743169
f1-score    0.696774    0.777251  0.743169    0.737013      0.750865
support    60.000000  123.000000  0.743169  183.000000    183.000000
[[54  6]
 [41 82]]

SUMMARY OF CLASSIFIERS PERFORMANCES OVER  TITANIC
                     precision    recall  f1-score support
AdaBoost              0.783136  0.786885  0.784375   183.0
Random Forest         0.782105  0.786885  0.783233   183.0
SVM Linear            0.776225  0.765027  0.768763   183.0
Decision Tree         0.751181  0.754098  0.752427   183.0
GSNAc                 0.812672  0.743169  0.750865   183.0
SVM RBF               0.748103  0.737705  0.741493   183.0
kNN                   0.722521  0.721311  0.721894   183.0
ANN - MLP             0.718348  0.715847  0.717012   183.0
Gaussian RBF          0.714253  0.710383  0.712127   183.0
Naive Bayes Gaussian  0.641138  0.497268  0.494295   183.0
Time elapsed in seconds:  29.70599365234375
